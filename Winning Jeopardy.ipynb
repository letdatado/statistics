{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Winning Jeopardy - An analysis on a sample of questions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![jeopardy](jeopardy.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction:\n",
    "[Jeopardy](https://www.jeopardy.com/) is a popular TV show in the US where participants answer questions to win money. It's been running for many years, and is a major force in popular culture.\n",
    "\n",
    "We'll work on a dataset that contains 20000 rows from the beginning of a full dataset of Jeopardy questions, which can be  downloaded from [here](https://www.reddit.com/r/datasets/comments/1uyd0t/200000_jeopardy_questions_in_a_json_file).\n",
    "\n",
    "### Data Dictionary\n",
    "|Column|Description|\n",
    "|:-----|:----------|\n",
    "|Show Number | the Jeopardy episode number|\n",
    "|Air Date | the date the episode aired|\n",
    "|Round | the round of Jeopardy|\n",
    "|Category | the category of the question|\n",
    "|Value | the number of dollars the correct answer is worth|\n",
    "|Question | the text of the question|\n",
    "|Answer | the text of the answer|\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Goal:\n",
    "We're looking for any way to win. In this project, we'll work with a dataset of Jeopardy questions to figure out some patterns in the questions that could help us win."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline \n",
    "import re\n",
    "\n",
    "from random import choice\n",
    "\n",
    "from scipy.stats import chisquare\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Exploring Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('jeopardy.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Show Number</th>\n",
       "      <th>Air Date</th>\n",
       "      <th>Round</th>\n",
       "      <th>Category</th>\n",
       "      <th>Value</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>HISTORY</td>\n",
       "      <td>$200</td>\n",
       "      <td>For the last 8 years of his life, Galileo was ...</td>\n",
       "      <td>Copernicus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>ESPN's TOP 10 ALL-TIME ATHLETES</td>\n",
       "      <td>$200</td>\n",
       "      <td>No. 2: 1912 Olympian; football star at Carlisl...</td>\n",
       "      <td>Jim Thorpe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EVERYBODY TALKS ABOUT IT...</td>\n",
       "      <td>$200</td>\n",
       "      <td>The city of Yuma in this state has a record av...</td>\n",
       "      <td>Arizona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>THE COMPANY LINE</td>\n",
       "      <td>$200</td>\n",
       "      <td>In 1963, live on \"The Art Linkletter Show\", th...</td>\n",
       "      <td>McDonald's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EPITAPHS &amp; TRIBUTES</td>\n",
       "      <td>$200</td>\n",
       "      <td>Signer of the Dec. of Indep., framer of the Co...</td>\n",
       "      <td>John Adams</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Show Number    Air Date      Round                         Category  Value  \\\n",
       "0         4680  2004-12-31  Jeopardy!                          HISTORY   $200   \n",
       "1         4680  2004-12-31  Jeopardy!  ESPN's TOP 10 ALL-TIME ATHLETES   $200   \n",
       "2         4680  2004-12-31  Jeopardy!      EVERYBODY TALKS ABOUT IT...   $200   \n",
       "3         4680  2004-12-31  Jeopardy!                 THE COMPANY LINE   $200   \n",
       "4         4680  2004-12-31  Jeopardy!              EPITAPHS & TRIBUTES   $200   \n",
       "\n",
       "                                            Question      Answer  \n",
       "0  For the last 8 years of his life, Galileo was ...  Copernicus  \n",
       "1  No. 2: 1912 Olympian; football star at Carlisl...  Jim Thorpe  \n",
       "2  The city of Yuma in this state has a record av...     Arizona  \n",
       "3  In 1963, live on \"The Art Linkletter Show\", th...  McDonald's  \n",
       "4  Signer of the Dec. of Indep., framer of the Co...  John Adams  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Show Number</th>\n",
       "      <th>Air Date</th>\n",
       "      <th>Round</th>\n",
       "      <th>Category</th>\n",
       "      <th>Value</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19994</th>\n",
       "      <td>3582</td>\n",
       "      <td>2000-03-14</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>U.S. GEOGRAPHY</td>\n",
       "      <td>$200</td>\n",
       "      <td>Of 8, 12 or 18, the number of U.S. states that...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>3582</td>\n",
       "      <td>2000-03-14</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>POP MUSIC PAIRINGS</td>\n",
       "      <td>$200</td>\n",
       "      <td>...&amp; the New Power Generation</td>\n",
       "      <td>Prince</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>3582</td>\n",
       "      <td>2000-03-14</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>HISTORIC PEOPLE</td>\n",
       "      <td>$200</td>\n",
       "      <td>In 1589 he was appointed professor of mathemat...</td>\n",
       "      <td>Galileo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>3582</td>\n",
       "      <td>2000-03-14</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>1998 QUOTATIONS</td>\n",
       "      <td>$200</td>\n",
       "      <td>Before the grand jury she said, \"I'm really so...</td>\n",
       "      <td>Monica Lewinsky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>3582</td>\n",
       "      <td>2000-03-14</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>LLAMA-RAMA</td>\n",
       "      <td>$200</td>\n",
       "      <td>Llamas are the heftiest South American members...</td>\n",
       "      <td>Camels</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Show Number    Air Date      Round            Category  Value  \\\n",
       "19994         3582  2000-03-14  Jeopardy!      U.S. GEOGRAPHY   $200   \n",
       "19995         3582  2000-03-14  Jeopardy!  POP MUSIC PAIRINGS   $200   \n",
       "19996         3582  2000-03-14  Jeopardy!     HISTORIC PEOPLE   $200   \n",
       "19997         3582  2000-03-14  Jeopardy!     1998 QUOTATIONS   $200   \n",
       "19998         3582  2000-03-14  Jeopardy!          LLAMA-RAMA   $200   \n",
       "\n",
       "                                                Question           Answer  \n",
       "19994  Of 8, 12 or 18, the number of U.S. states that...               18  \n",
       "19995                      ...& the New Power Generation           Prince  \n",
       "19996  In 1589 he was appointed professor of mathemat...          Galileo  \n",
       "19997  Before the grand jury she said, \"I'm really so...  Monica Lewinsky  \n",
       "19998  Llamas are the heftiest South American members...           Camels  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19999 entries, 0 to 19998\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Show Number  19999 non-null  int64 \n",
      " 1    Air Date    19999 non-null  object\n",
      " 2    Round       19999 non-null  object\n",
      " 3    Category    19999 non-null  object\n",
      " 4    Value       19999 non-null  object\n",
      " 5    Question    19999 non-null  object\n",
      " 6    Answer      19999 non-null  object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We do not have Null values\n",
    "- Except for `Show Number`, all the columns are in object Dtype.\n",
    "    - `Value` and `Air Date` are intrinsically of int and Date Dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Show Number', ' Air Date', ' Round', ' Category', ' Value',\n",
       "       ' Question', ' Answer'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Most column names come with a leading space in their names."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fix these issues and others, lets move onto Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "- Normalize all of the text columns (the `Question` and `Answer` columns) by\n",
    "    - Lower case all the words\n",
    "    - Remove all the punctuations\n",
    "\n",
    "- Normalize the `Value` and `Air Date` columns. The former should be numeric and the latter should be datetime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove leading spaces from column names\n",
    "data.columns  = data.columns.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Show Number', 'Air Date', 'Round', 'Category', 'Value', 'Question',\n",
       "       'Answer'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_string(string):\n",
    "    '''\n",
    "    Normalizes the text by lower casing, \n",
    "    removing punctuations the text\n",
    "    \n",
    "    Args:\n",
    "        string: str; text to normalize\n",
    "        \n",
    "    Returns:\n",
    "        str; Normalized text\n",
    "    '''\n",
    "    string = string.lower() # Lower case. \n",
    "    string = re.sub('[^A-Za-z0-9\\s]', '', string) # Remove all puntuations.\n",
    "    string = re.sub('\\s+', ' ', string) # Remove extra spaces.\n",
    "    \n",
    "    return string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets apply normalize_string() on `Question` and `Answer` columns and normalize them into new columns `clean_question` and `clean answer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column Question\n",
    "data['clean_question'] = data['Question'].apply(normalize_string)\n",
    "\n",
    "# Column Answer\n",
    "data['clean_answer'] = data['Answer'].apply(normalize_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_question</th>\n",
       "      <th>Question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>for the last 8 years of his life galileo was u...</td>\n",
       "      <td>For the last 8 years of his life, Galileo was ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no 2 1912 olympian football star at carlisle i...</td>\n",
       "      <td>No. 2: 1912 Olympian; football star at Carlisl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the city of yuma in this state has a record av...</td>\n",
       "      <td>The city of Yuma in this state has a record av...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>in 1963 live on the art linkletter show this c...</td>\n",
       "      <td>In 1963, live on \"The Art Linkletter Show\", th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>signer of the dec of indep framer of the const...</td>\n",
       "      <td>Signer of the Dec. of Indep., framer of the Co...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      clean_question  \\\n",
       "0  for the last 8 years of his life galileo was u...   \n",
       "1  no 2 1912 olympian football star at carlisle i...   \n",
       "2  the city of yuma in this state has a record av...   \n",
       "3  in 1963 live on the art linkletter show this c...   \n",
       "4  signer of the dec of indep framer of the const...   \n",
       "\n",
       "                                            Question  \n",
       "0  For the last 8 years of his life, Galileo was ...  \n",
       "1  No. 2: 1912 Olympian; football star at Carlisl...  \n",
       "2  The city of Yuma in this state has a record av...  \n",
       "3  In 1963, live on \"The Art Linkletter Show\", th...  \n",
       "4  Signer of the Dec. of Indep., framer of the Co...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check Question\n",
    "data[['clean_question','Question']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_answer</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>copernicus</td>\n",
       "      <td>Copernicus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jim thorpe</td>\n",
       "      <td>Jim Thorpe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>arizona</td>\n",
       "      <td>Arizona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mcdonalds</td>\n",
       "      <td>McDonald's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>john adams</td>\n",
       "      <td>John Adams</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  clean_answer      Answer\n",
       "0   copernicus  Copernicus\n",
       "1   jim thorpe  Jim Thorpe\n",
       "2      arizona     Arizona\n",
       "3    mcdonalds  McDonald's\n",
       "4   john adams  John Adams"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check Question\n",
    "data[['clean_answer','Answer']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_value(string):\n",
    "    '''\n",
    "    Normalizes the string by removing \n",
    "    punctuations including the USD sign\n",
    "    and tries to convert it into int.\n",
    "    If it doesn't convert, value 0 is\n",
    "    assigned\n",
    "    \n",
    "    Args:\n",
    "        string: str; string\n",
    "        \n",
    "    Returns:\n",
    "        int; the numeric value, or 0\n",
    "    '''\n",
    "    value = re.sub('[^\\w\\s]','',string) # regex pattern \n",
    "    \n",
    "    try: \n",
    "        value=int(value) # to convert numbers in string into integers\n",
    "    except Exception: \n",
    "        value=0  # Assigning 0 in case of exception\n",
    "   \n",
    "    return value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets apply normalize_value() on `Value` and normalize it into a new column `clean_value` and Convert `Air Date` into datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column Value\n",
    "data['clean_value'] = data['Value'].apply(normalize_value)\n",
    "\n",
    "# Column Air Date Conversion into datetime \n",
    "data['Air Date'] = pd.to_datetime(data['Air Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "      <th>clean_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>$200</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>$200</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>$200</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>$200</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>$200</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Value  clean_value\n",
       "0  $200          200\n",
       "1  $200          200\n",
       "2  $200          200\n",
       "3  $200          200\n",
       "4  $200          200"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check\n",
    "data[['Value', 'clean_value']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to figure out whether to study past questions, study general knowledge, or not study it all, it would be helpful to figure out two things:\n",
    "\n",
    "- How often the answer can be used for a question.\n",
    "- How often questions are repeated.\n",
    "\n",
    "We can answer the second question by seeing how often complex words (> 6 characters) reoccur. We can answer the first question by seeing how many times words in the answer also occur in the question. We'll work on the first question and come back to the second.\n",
    "\n",
    "### What are the chances that the answer is found in the question itself?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_counter(row): \n",
    "    '''\n",
    "    Takes in a row in DataFrame as a \n",
    "    Series andcounts how many words \n",
    "    occur in question as well as its \n",
    "    answer.\n",
    "    Args:\n",
    "        row: DataFrame, row.\n",
    "    Returns:\n",
    "        float; density of co-occuring words in \n",
    "        the answer\n",
    "    '''\n",
    "    # Splits the strings\n",
    "    split_question = row['clean_question'].split()  \n",
    "    split_answer = row['clean_answer'].split()\n",
    "    \n",
    "    # Counter to count co occurences\n",
    "    match_count = 0\n",
    "    \n",
    "    if 'the' in split_answer: # ignore word 'the'. \n",
    "        split_answer.remove('the')\n",
    "    \n",
    "    if len(split_answer) == 0:\n",
    "        return 0 # prevent division by zero error\n",
    "    \n",
    "    # Loop through both \n",
    "    for word in split_answer:\n",
    "        if word in split_question:\n",
    "            match_count += 1 # count\n",
    "            \n",
    "    return match_count / len(split_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets count how many times terms in `clean_answer` occur in `clean_question` and assign the result of each row to a new column\n",
    "`answer_in_question`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply to whole dataframe and pass the axis=1 argument to apply the function across each row.\n",
    "data['answer_in_question'] = data.apply(match_counter, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.059001965249777744"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate Mean\n",
    "data['answer_in_question'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- On average, 6% words occur in questions as well as in the answers. In other words, there is only a 6% chance that the answer also repeats itself in its question. Therefore, one should not suppose to get the answer of a question within the words of the question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  How often new questions are repeats of older ones?\n",
    "Given that we only have a fraction of (10%) of the full Jeopardy question dataset, we can't answer it completely. However, an investigation can be done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6876260592169776"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_overlap = []\n",
    "terms_used = set()\n",
    "\n",
    "# Sort the data in ascending order with respect to Air Date\n",
    "data = data.sort_values(by='Air Date')\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "    split_question = row['clean_question'].split(' ')\n",
    "    \n",
    "    # an arbitrary value to filter out words like 'the', 'is' etc\n",
    "    split_question = [q for q in split_question if len(q) > 5]\n",
    "    \n",
    "    match_count = 0\n",
    "    for word in split_question:\n",
    "        if word in terms_used:\n",
    "            match_count += 1\n",
    "    for word in split_question:\n",
    "        terms_used.add(word)\n",
    "    if len(split_question) > 0:\n",
    "        match_count /= len(split_question)\n",
    "    question_overlap.append(match_count)\n",
    "        \n",
    "data['question_overlap'] = question_overlap\n",
    "\n",
    "# Mean of the column\n",
    "data['question_overlap'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- So we have 69% meaningful words overlap in questions. Though it represents the overlap on only 10% of the questions of the full jeopardy dataset, there is indeed some question recycling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are the trends of High-Value questions?\n",
    "\n",
    "First, lets categorize the questions into high-value and low-value questions and then, by looping through the set 'terms used' we made earlier, lets\n",
    "- Find the number of low value questions the word occurs in.\n",
    "- Find the number of high value questions the word occurs in.\n",
    "- Find the percentage of questions the word occurs in.\n",
    "- Based on the percentage of questions the word occurs in, find expected counts.\n",
    "- Compute the chi squared value based on the expected counts and the observed counts for high and low value questions.\n",
    "- We can then find the words with the biggest differences in usage between high and low value questions, by selecting the words with the highest associated chi-squared values. Doing this for all of the words would take a very long time, so we'll just do it for a small sample now.\n",
    "\n",
    "To look into the questions's values, lets get into `clean_value` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "748.3362668133407"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean of questions' values\n",
    "data['clean_value'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets narrow down the questions into two categories:\n",
    "\n",
    "- Low value: Any row where Value is less than 800.\n",
    "- High value: Any row where Value is greater than 800."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_value(row):\n",
    "    '''\n",
    "    Takes in a row in DataFrame as a \n",
    "    Series and categorizes question \n",
    "    as either of high or low value with\n",
    "    a bar is set on 800.\n",
    "    Args:\n",
    "        row: row\n",
    "    Returns:\n",
    "        bool; 1 if True and 0 if False\n",
    "    '''\n",
    "    if row['clean_value'] > 800:\n",
    "        return 1\n",
    "    # else\n",
    "    return 0\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    14265\n",
       "1     5734\n",
       "Name: high_value, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the function \n",
    "data['high_value'] = data.apply(get_value, axis=1)\n",
    "\n",
    "# Check\n",
    "data['high_value'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_values(word):\n",
    "    '''\n",
    "    count the number of high and low valued questions \n",
    "    the word occures in\n",
    "    Args:\n",
    "        word: a word in string\n",
    "    Returns:\n",
    "        returns the count of high and low valued questions\n",
    "    '''\n",
    "    low_count = 0\n",
    "    high_count = 0\n",
    "    for i, row in data.iterrows():\n",
    "        split_question = row['clean_question'].split(' ')\n",
    "        if word in split_question:\n",
    "            if row['high_value'] == 1:\n",
    "                high_count += 1\n",
    "            else:\n",
    "                low_count += 1\n",
    "    return high_count, low_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets choose some words from the set 'terms_used' randomly and see how many times they appear in high-valued and low-valued questions each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['carassos',\n",
       " 'abagnale',\n",
       " 'respect',\n",
       " 'balances',\n",
       " 'muchsought',\n",
       " '10sup23sup',\n",
       " 'binghams',\n",
       " 'longitude',\n",
       " 'ranklesa',\n",
       " 'serenading']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from random import choice\n",
    "comparison_terms = []\n",
    "\n",
    "# Lets choose 10 words randomly\n",
    "for i in range(10): \n",
    "    comparison_terms.append(choice(list(terms_used))) \n",
    "\n",
    "comparison_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1),\n",
       " (1, 1),\n",
       " (2, 6),\n",
       " (0, 1),\n",
       " (0, 1),\n",
       " (1, 1),\n",
       " (1, 0),\n",
       " (1, 1),\n",
       " (1, 0),\n",
       " (0, 1)]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the results into a list\n",
    "observed_expected = []\n",
    "\n",
    "for term in comparison_terms:\n",
    "    observed_expected.append(count_values(term)) # Apply the recently made function\n",
    "\n",
    "# see the results\n",
    "observed_expected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying Chi-Squared Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of rows of each isolated set of data, i-e, high-valued and low-valued questions \n",
    "high_value_count = data[data['high_value'] == 1].shape[0]\n",
    "low_value_count = data[data['high_value'] == 0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Power_divergenceResult(statistic=0.401962846126884, pvalue=0.5260772985705469),\n",
       " Power_divergenceResult(statistic=0.4448774816612795, pvalue=0.5047776487545996),\n",
       " Power_divergenceResult(statistic=0.05272886616881538, pvalue=0.818381104912348),\n",
       " Power_divergenceResult(statistic=0.401962846126884, pvalue=0.5260772985705469),\n",
       " Power_divergenceResult(statistic=0.401962846126884, pvalue=0.5260772985705469),\n",
       " Power_divergenceResult(statistic=0.4448774816612795, pvalue=0.5047776487545996),\n",
       " Power_divergenceResult(statistic=2.487792117195675, pvalue=0.11473257634454047),\n",
       " Power_divergenceResult(statistic=0.4448774816612795, pvalue=0.5047776487545996),\n",
       " Power_divergenceResult(statistic=2.487792117195675, pvalue=0.11473257634454047),\n",
       " Power_divergenceResult(statistic=0.401962846126884, pvalue=0.5260772985705469)]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from scipy.stats import chisquare\n",
    "chi_squared = []\n",
    "\n",
    "for observation in observed_expected:\n",
    "    total = observation[0] + observation[1] # Summing up the pair\n",
    "    total_prop = total/data.shape[0] # Dividing variable total by the total rows in entire df\n",
    "    \n",
    "    # Expected Term Counts for high-value and low_value counts\n",
    "    high_value_expected = total_prop * high_value_count\n",
    "    low_value_expected = total_prop * low_value_count\n",
    "    \n",
    "    # Chi-Squared value and p-value given the expected and observed counts.\n",
    "    observed = np.array([observation[0], observation[1]])\n",
    "    expected = np.array([high_value_expected, low_value_expected])\n",
    "    \n",
    "    # Calculate and Append tp the list chi_squared\n",
    "    chi_squared.append(chisquare(observed, expected))\n",
    "\n",
    "chi_squared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- None of the calculated p-values are less than 0.05. Therefore there is no signficant dfifference between observed and expected values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which categories appear the most often and what is the probability of each category appearing in each round?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each game of Jeopardy! features three contestants competing in three rounds: \n",
    "1. Jeopardy! \n",
    "2. Double Jeopardy! and \n",
    "3. Final Jeopardy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TELEVISION             51\n",
       "U.S. GEOGRAPHY         50\n",
       "LITERATURE             45\n",
       "AMERICAN HISTORY       40\n",
       "HISTORY                40\n",
       "                       ..\n",
       "UP YOUR \"ALLEY\"         1\n",
       "EXPLORATION             1\n",
       "ROCK SONGS              1\n",
       "RIVERS                  1\n",
       "SPORTS & THE MOVIES     1\n",
       "Name: Category, Length: 3581, dtype: int64"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Category'].value_counts(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There are around 3581 different categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Most common Categories for each round  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUND: Final Jeopardy!\n",
      "WORD ORIGINS         8\n",
      "U.S. PRESIDENTS      5\n",
      "FAMOUS NAMES         4\n",
      "AUTHORS              4\n",
      "SPACE EXPLORATION    3\n",
      "ASIA                 3\n",
      "FAMOUS WOMEN         3\n",
      "U.S. STATES          3\n",
      "WORLD GEOGRAPHY      3\n",
      "THE 50 STATES        3\n",
      "Name: Category, dtype: int64\n",
      "--------------------\n",
      "ROUND: Double Jeopardy!\n",
      "LITERATURE           35\n",
      "SCIENCE & NATURE     30\n",
      "ISLANDS              30\n",
      "BEFORE & AFTER       30\n",
      "IN THE DICTIONARY    30\n",
      "U.S. GEOGRAPHY       28\n",
      "OPERA                25\n",
      "HISTORIC NAMES       25\n",
      "WORLD CAPITALS       25\n",
      "SCIENCE              25\n",
      "Name: Category, dtype: int64\n",
      "--------------------\n",
      "ROUND: Jeopardy!\n",
      "TELEVISION        35\n",
      "SPORTS            26\n",
      "FOOD FACTS        25\n",
      "RHYME TIME        25\n",
      "U.S. CITIES       25\n",
      "BIRDS             23\n",
      "U.S. GEOGRAPHY    22\n",
      "COMMON BONDS      20\n",
      "MUSEUMS           20\n",
      "BRAND NAMES       20\n",
      "Name: Category, dtype: int64\n",
      "--------------------\n",
      "ROUND: Tiebreaker\n",
      "CHILD'S PLAY    1\n",
      "Name: Category, dtype: int64\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "for each_round in data['Round'].unique():\n",
    "    print('ROUND:',each_round)\n",
    "    print(data[data['Round'] == each_round]['Category'].value_counts()[:10])\n",
    "    print('-'*20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUND: Final Jeopardy!\n",
      "WORD ORIGINS         0.023881\n",
      "U.S. PRESIDENTS      0.014925\n",
      "FAMOUS NAMES         0.011940\n",
      "AUTHORS              0.011940\n",
      "SPACE EXPLORATION    0.008955\n",
      "ASIA                 0.008955\n",
      "FAMOUS WOMEN         0.008955\n",
      "U.S. STATES          0.008955\n",
      "WORLD GEOGRAPHY      0.008955\n",
      "THE 50 STATES        0.008955\n",
      "Name: Category, dtype: float64\n",
      "--------------------\n",
      "ROUND: Double Jeopardy!\n",
      "LITERATURE           0.003585\n",
      "SCIENCE & NATURE     0.003073\n",
      "ISLANDS              0.003073\n",
      "BEFORE & AFTER       0.003073\n",
      "IN THE DICTIONARY    0.003073\n",
      "U.S. GEOGRAPHY       0.002868\n",
      "OPERA                0.002561\n",
      "HISTORIC NAMES       0.002561\n",
      "WORLD CAPITALS       0.002561\n",
      "SCIENCE              0.002561\n",
      "Name: Category, dtype: float64\n",
      "--------------------\n",
      "ROUND: Jeopardy!\n",
      "TELEVISION        0.003535\n",
      "SPORTS            0.002626\n",
      "FOOD FACTS        0.002525\n",
      "RHYME TIME        0.002525\n",
      "U.S. CITIES       0.002525\n",
      "BIRDS             0.002323\n",
      "U.S. GEOGRAPHY    0.002222\n",
      "COMMON BONDS      0.002020\n",
      "MUSEUMS           0.002020\n",
      "BRAND NAMES       0.002020\n",
      "Name: Category, dtype: float64\n",
      "--------------------\n",
      "ROUND: Tiebreaker\n",
      "CHILD'S PLAY    1.0\n",
      "Name: Category, dtype: float64\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "# Lets look into the probabilities \n",
    "for each_round in data['Round'].unique():\n",
    "    print('ROUND:',each_round)\n",
    "    print(data[data['Round'] == each_round]['Category'].value_counts(normalize=True)[:10])\n",
    "    print('-'*20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In the first round, *Jeopardy!*, most of the questions belonged to categories like Televsion, Sports, Food facts, Rhyme Time, U.S cities, Birds, U.S Geography, museums and Brand names. We can observe by looking at the categories that they do not require the contestant to have advanced knowledge. Categories are very general and 'surface level' of knowledge should be good enough to compete in Round 1.\n",
    "- Whereas in the second round, *Double Jeopardy!*, the categories seem a bit more demanding for knowledge of the contestant. Categories like, Literature, Science, Islands, U.S. Geography, Historical names, World Captials and Opera are not part of 'everyone's interest'. Most common categories are Literature, Science and Nature, Before and After and Islands\n",
    "- The final round, 'Final Jeopardy! comprises of some domain-specific categories like Word's origins, Space Exploration, U.S Presidents, Authors' names and Asia. Most commonly asked questions are from the categories of Words origins, U.S presidents, Authors and Famous names\n",
    "\n",
    "However, The probabilities are too low to be considered. We can not do the 'guess work' about which category we might be facing our question from given such probabilities."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
